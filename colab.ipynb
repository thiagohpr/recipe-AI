{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP0IrcR4U6Za",
        "outputId": "0cc6463d-e007-4231-e5c3-02159851edf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/MyDrive/dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfeUp3F6xLz1",
        "outputId": "280d337b-f16a-4299-b58a-064d94100697"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/dataset.zip\n",
            "   creating: dataset/train/\n",
            "   creating: dataset/train/abacaxi/\n",
            "  inflating: dataset/train/abacaxi/Abacaxi.JPEG  \n",
            "  inflating: dataset/train/abacaxi/Abacaxi2.JPEG  \n",
            "  inflating: dataset/train/abacaxi/Abacaxi3.JPEG  \n",
            "  inflating: dataset/train/abacaxi/Abacaxi4.JPEG  \n",
            "   creating: dataset/train/abobrinha/\n",
            "  inflating: dataset/train/abobrinha/Abobrinha.JPEG  \n",
            "  inflating: dataset/train/abobrinha/Abobrinha2.JPEG  \n",
            "  inflating: dataset/train/abobrinha/Abobrinha3.JPEG  \n",
            "   creating: dataset/train/alface/\n",
            "  inflating: dataset/train/alface/Alface.JPEG  \n",
            "  inflating: dataset/train/alface/Alface2.JPEG  \n",
            "  inflating: dataset/train/alface/Alface3.JPEG  \n",
            "   creating: dataset/train/alho/\n",
            "  inflating: dataset/train/alho/Alho.JPEG  \n",
            "  inflating: dataset/train/alho/Alho2.JPEG  \n",
            "  inflating: dataset/train/alho/Alho3.JPEG  \n",
            "   creating: dataset/train/arroz/\n",
            "  inflating: dataset/train/arroz/Arroz.JPEG  \n",
            "  inflating: dataset/train/arroz/Arroz2.JPEG  \n",
            "  inflating: dataset/train/arroz/Arroz3.JPEG  \n",
            "   creating: dataset/train/aveia/\n",
            "  inflating: dataset/train/aveia/Aveia.JPEG  \n",
            "  inflating: dataset/train/aveia/Aveia2.JPEG  \n",
            "  inflating: dataset/train/aveia/Aveia3.JPEG  \n",
            "   creating: dataset/train/bacon/\n",
            "  inflating: dataset/train/bacon/Bacon.JPEG  \n",
            "  inflating: dataset/train/bacon/Bacon2.JPEG  \n",
            "  inflating: dataset/train/bacon/Bacon3.JPEG  \n",
            "  inflating: dataset/train/bacon/Bacon4.JPEG  \n",
            "   creating: dataset/train/banana/\n",
            "  inflating: dataset/train/banana/Banana.JPEG  \n",
            "  inflating: dataset/train/banana/Banana2.JPEG  \n",
            "  inflating: dataset/train/banana/Banana3.JPEG  \n",
            "   creating: dataset/train/batata/\n",
            "  inflating: dataset/train/batata/Batata.JPEG  \n",
            "  inflating: dataset/train/batata/Batata2.JPEG  \n",
            "  inflating: dataset/train/batata/Batata3.JPEG  \n",
            "  inflating: dataset/train/batata/Batata4.JPEG  \n",
            "   creating: dataset/train/biscoito_oreo/\n",
            "  inflating: dataset/train/biscoito_oreo/Biscoito_oreo.JPEG  \n",
            "  inflating: dataset/train/biscoito_oreo/Biscoito_oreo2.JPEG  \n",
            "  inflating: dataset/train/biscoito_oreo/Biscoito_oreo3.JPEG  \n",
            "  inflating: dataset/train/biscoito_oreo/Biscoito_oreo4.JPEG  \n",
            "   creating: dataset/train/brocolis/\n",
            "  inflating: dataset/train/brocolis/Brocolis.JPEG  \n",
            "  inflating: dataset/train/brocolis/Brocolis2.JPEG  \n",
            "  inflating: dataset/train/brocolis/Brocolis3.JPEG  \n",
            "  inflating: dataset/train/brocolis/Brocolis4.JPEG  \n",
            "   creating: dataset/train/chocolate/\n",
            "  inflating: dataset/train/chocolate/Chocolate_ao_leite.JPEG  \n",
            "  inflating: dataset/train/chocolate/Chocolate_ao_leite2.JPEG  \n",
            "  inflating: dataset/train/chocolate/Chocolate_ao_leite3.JPEG  \n",
            "  inflating: dataset/train/chocolate/Chocolate_ao_leite4.JPEG  \n",
            "  inflating: dataset/train/chocolate/Chocolate_ao_leite5.JPEG  \n",
            "   creating: dataset/train/couve_flor/\n",
            "  inflating: dataset/train/couve_flor/Couve_flor.JPEG  \n",
            "  inflating: dataset/train/couve_flor/Couve_flor2.JPEG  \n",
            "  inflating: dataset/train/couve_flor/Couve_flor3.JPEG  \n",
            "   creating: dataset/train/filet_mignon/\n",
            "  inflating: dataset/train/filet_mignon/File_mignon.JPEG  \n",
            "  inflating: dataset/train/filet_mignon/File_mignon2.JPEG  \n",
            "  inflating: dataset/train/filet_mignon/File_mignon3.JPEG  \n",
            "   creating: dataset/train/ketchup/\n",
            "  inflating: dataset/train/ketchup/Ketchup.JPEG  \n",
            "  inflating: dataset/train/ketchup/Ketchup2.JPEG  \n",
            "  inflating: dataset/train/ketchup/Ketchup3.JPEG  \n",
            "  inflating: dataset/train/ketchup/Ketchup4.JPEG  \n",
            "   creating: dataset/train/laranja/\n",
            "  inflating: dataset/train/laranja/Laranja.JPEG  \n",
            "  inflating: dataset/train/laranja/Laranja2.JPEG  \n",
            "  inflating: dataset/train/laranja/Laranja3.JPEG  \n",
            "   creating: dataset/train/leite/\n",
            "  inflating: dataset/train/leite/Leite.JPEG  \n",
            "  inflating: dataset/train/leite/Leite2.JPEG  \n",
            "  inflating: dataset/train/leite/Leite3.JPEG  \n",
            "  inflating: dataset/train/leite/Leite4.JPEG  \n",
            "   creating: dataset/train/limao/\n",
            "  inflating: dataset/train/limao/Limao.JPEG  \n",
            "  inflating: dataset/train/limao/Limao2.JPEG  \n",
            "  inflating: dataset/train/limao/Limao3.JPEG  \n",
            "   creating: dataset/train/linguica/\n",
            "  inflating: dataset/train/linguica/LinguiЗa.JPEG  \n",
            "  inflating: dataset/train/linguica/LinguiЗa2.JPEG  \n",
            "  inflating: dataset/train/linguica/LinguiЗa3.JPEG  \n",
            "  inflating: dataset/train/linguica/LinguiЗa4.JPEG  \n",
            "   creating: dataset/train/maca/\n",
            "  inflating: dataset/train/maca/Maca.JPEG  \n",
            "  inflating: dataset/train/maca/Maca2.JPEG  \n",
            "  inflating: dataset/train/maca/Maca3.JPEG  \n",
            "  inflating: dataset/train/maca/Maca4.JPEG  \n",
            "  inflating: dataset/train/maca/Maca5.JPEG  \n",
            "   creating: dataset/train/macarrao/\n",
            "  inflating: dataset/train/macarrao/Macarrao.JPEG  \n",
            "  inflating: dataset/train/macarrao/Macarrao2.JPEG  \n",
            "  inflating: dataset/train/macarrao/Macarrao3.JPEG  \n",
            "  inflating: dataset/train/macarrao/Macarrao4.JPEG  \n",
            "   creating: dataset/train/manteiga/\n",
            "  inflating: dataset/train/manteiga/Manteiga.JPEG  \n",
            "  inflating: dataset/train/manteiga/Manteiga2.JPEG  \n",
            "  inflating: dataset/train/manteiga/Manteiga3.JPEG  \n",
            "  inflating: dataset/train/manteiga/Manteiga4.JPEG  \n",
            "   creating: dataset/train/mortadela/\n",
            "  inflating: dataset/train/mortadela/Mortadela.JPEG  \n",
            "  inflating: dataset/train/mortadela/Mortadela2.JPEG  \n",
            "  inflating: dataset/train/mortadela/Mortadela3.JPEG  \n",
            "   creating: dataset/train/mostarda/\n",
            "  inflating: dataset/train/mostarda/Mostarda.JPEG  \n",
            "  inflating: dataset/train/mostarda/Mostarda2.JPEG  \n",
            "  inflating: dataset/train/mostarda/Mostarda3.JPEG  \n",
            "   creating: dataset/train/ovo/\n",
            "  inflating: dataset/train/ovo/Ovos.JPEG  \n",
            "  inflating: dataset/train/ovo/Ovos2.JPEG  \n",
            "  inflating: dataset/train/ovo/Ovos3.JPEG  \n",
            "   creating: dataset/train/pao/\n",
            "  inflating: dataset/train/pao/Pao_de_forma.JPEG  \n",
            "  inflating: dataset/train/pao/Pao_de_forma2.JPEG  \n",
            "  inflating: dataset/train/pao/Pao_de_forma3.JPEG  \n",
            "   creating: dataset/train/pera/\n",
            "  inflating: dataset/train/pera/Pera.JPEG  \n",
            "  inflating: dataset/train/pera/Pera2.JPEG  \n",
            "  inflating: dataset/train/pera/Pera3.JPEG  \n",
            "  inflating: dataset/train/pera/Pera4.JPEG  \n",
            "  inflating: dataset/train/pera/Pera5.JPEG  \n",
            "   creating: dataset/train/queijo_mussarela/\n",
            "  inflating: dataset/train/queijo_mussarela/Queijo_mussarela.JPEG  \n",
            "  inflating: dataset/train/queijo_mussarela/Queijo_mussarela2.JPEG  \n",
            "  inflating: dataset/train/queijo_mussarela/Queijo_mussarela3.JPEG  \n",
            "  inflating: dataset/train/queijo_mussarela/Queijo_mussarela4.JPEG  \n",
            "   creating: dataset/train/salmao/\n",
            "  inflating: dataset/train/salmao/Salm╞o.JPEG  \n",
            "  inflating: dataset/train/salmao/Salm╞o2.JPEG  \n",
            "  inflating: dataset/train/salmao/Salm╞o3.JPEG  \n",
            "  inflating: dataset/train/salmao/Salm╞o4.JPEG  \n",
            "   creating: dataset/train/sobrecoxa_frango/\n",
            "  inflating: dataset/train/sobrecoxa_frango/Sobrecoxa_de_frango.JPEG  \n",
            "  inflating: dataset/train/sobrecoxa_frango/Sobrecoxa_de_frango2.JPEG  \n",
            "  inflating: dataset/train/sobrecoxa_frango/Sobrecoxa_de_frango3.JPEG  \n",
            "  inflating: dataset/train/sobrecoxa_frango/Sobrecoxa_de_frango4.JPEG  \n",
            "   creating: dataset/train/sucrilhos/\n",
            "  inflating: dataset/train/sucrilhos/Sucrilhos.JPEG  \n",
            "  inflating: dataset/train/sucrilhos/Sucrilhos2.JPEG  \n",
            "  inflating: dataset/train/sucrilhos/Sucrilhos3.JPEG  \n",
            "  inflating: dataset/train/sucrilhos/Sucrilhos4.JPEG  \n",
            "   creating: dataset/train/tomate/\n",
            "  inflating: dataset/train/tomate/Tomate.JPEG  \n",
            "  inflating: dataset/train/tomate/Tomate2.JPEG  \n",
            "  inflating: dataset/train/tomate/Tomate3.JPEG  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub7QTbmCyZE0",
        "outputId": "71affc9d-6646-41c7-9695-09614f9aa961"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# path = \"dataset\"\n",
        "\n",
        "# file_list = []\n",
        "\n",
        "# for root, dirs, files in os.walk(path):\n",
        "#     print('Root : ', root)\n",
        "#     print('Dirs : ', dirs)\n",
        "#     print('Files : ', files)\n"
      ],
      "metadata": {
        "id": "VAmgPl0npH9B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import glob # to find files recursively\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "C2JzPeaWwOP1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255., # Rescaling\n",
        "    rotation_range = 40, # for augmentation\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True\n",
        ")"
      ],
      "metadata": {
        "id": "wjWPGheqwhUG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'dataset/train/'\n",
        "image_size = (1536, 2048)\n",
        "batch_size = 16\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    target_size = image_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmrBRiUjwnUE",
        "outputId": "acca81b9-3cdf-4880-9cdc-594a30a9eba8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 116 images belonging to 32 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def plotImages(images_arr):\n",
        "#     fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "#     axes = axes.flatten()\n",
        "#     for img, ax in zip( images_arr, axes):\n",
        "#         ax.imshow(img)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "# augmented_images = [train_generator[0][0][0] for i in range(10)]\n",
        "# plotImages(augmented_images)\n",
        "\n",
        "train_generator[0][0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1_Jr_4SzvZq",
        "outputId": "9bf7667c-3c21-4a31-b473-1987536841c7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1536, 2048, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5YvWHHE0CRM",
        "outputId": "5b928f73-998d-4868-f97b-5eaafb7371fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'abacaxi',\n",
              " 1: 'abobrinha',\n",
              " 2: 'alface',\n",
              " 3: 'alho',\n",
              " 4: 'arroz',\n",
              " 5: 'aveia',\n",
              " 6: 'bacon',\n",
              " 7: 'banana',\n",
              " 8: 'batata',\n",
              " 9: 'biscoito_oreo',\n",
              " 10: 'brocolis',\n",
              " 11: 'chocolate',\n",
              " 12: 'couve_flor',\n",
              " 13: 'filet_mignon',\n",
              " 14: 'ketchup',\n",
              " 15: 'laranja',\n",
              " 16: 'leite',\n",
              " 17: 'limao',\n",
              " 18: 'linguica',\n",
              " 19: 'maca',\n",
              " 20: 'macarrao',\n",
              " 21: 'manteiga',\n",
              " 22: 'mortadela',\n",
              " 23: 'mostarda',\n",
              " 24: 'ovo',\n",
              " 25: 'pao',\n",
              " 26: 'pera',\n",
              " 27: 'queijo_mussarela',\n",
              " 28: 'salmao',\n",
              " 29: 'sobrecoxa_frango',\n",
              " 30: 'sucrilhos',\n",
              " 31: 'tomate'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_classes = len(labels)"
      ],
      "metadata": {
        "id": "mO6mbfQV0OLV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "oUQiokT_0O2B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=(1536, 2048, 3)))\n",
        "# model.add(Conv2D(32, kernel_size=(5, 5), activation='relu'))\n",
        "# model.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))\n",
        "# model.add(Conv2D(128, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(Flatten())\n",
        "# model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "# Display a model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "aLRl9HnF0o5r",
        "outputId": "12d8be20-dcd4-4cd8-f7eb-ffb10c4e2728"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[50102528,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4d7a775373a9>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# model.add(Dense(16, activation='relu'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Display a model summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m                 \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateless_fold_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m             return tf.random.stateless_uniform(\n\u001b[0m\u001b[1;32m   2101\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                 \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[50102528,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2] name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy']\n",
        "             )\n",
        "\n",
        "# Start training\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        epochs = 10,\n",
        "        shuffle = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fKDcA_Kz09dZ",
        "outputId": "13530b5d-d24c-4e20-af71-0ed755468c20"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node sequential_7/conv2d_25/Relu defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-17-d28ad49f9ea2>\", line 7, in <cell line: 7>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5395, in relu\n\nOOM when allocating tensor with shape[16,16,1532,2044] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_7/conv2d_25/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1770]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d28ad49f9ea2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node sequential_7/conv2d_25/Relu defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-17-d28ad49f9ea2>\", line 7, in <cell line: 7>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5395, in relu\n\nOOM when allocating tensor with shape[16,16,1532,2044] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_7/conv2d_25/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1770]"
          ]
        }
      ]
    }
  ]
}